{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sys\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import vq2d.stats as vq_stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "params = {\n",
    "    \"legend.fontsize\": \"xx-large\",\n",
    "    \"axes.labelsize\": \"xx-large\",\n",
    "    \"axes.titlesize\":\"xx-large\",\n",
    "    \"xtick.labelsize\": \"xx-large\",\n",
    "    \"ytick.labelsize\": \"xx-large\",\n",
    "    \"text.color\": \"black\",\n",
    "    \"axes.labelcolor\": \"black\",\n",
    "    \"xtick.color\": \"black\",\n",
    "    \"ytick.color\": \"black\"\n",
    "}\n",
    "pylab.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to videos and VQ annotations\n",
    "ANNOT_PATHS = [\n",
    "    \"../data/vq_train.json\",\n",
    "    \"../data/vq_val.json\",\n",
    "    \"../data/vq_test.json\",\n",
    "]\n",
    "EGO4D_VIDEOS_ROOT = \"<TODO: UPDATE EGO4D VIDEOS PATH>\"\n",
    "STATS_DIR = \"./stats\"\n",
    "os.makedirs(STATS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the statistics of the VQ2D annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load annotations for each video\n",
    "VIDEO_ANNOTATIONS = []\n",
    "for annot_path in ANNOT_PATHS:\n",
    "    with open(annot_path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "    for v in data[\"videos\"]:\n",
    "        VIDEO_ANNOTATIONS.append(v)\n",
    "\n",
    "# Load metadata for each video\n",
    "manifest_path = os.path.join(EGO4D_VIDEOS_ROOT, \"manifest.csv\")\n",
    "manifest = pd.read_csv(manifest_path)\n",
    "VIDEO_UIDS_TO_METADATA = {v['video_uid']: None for v in VIDEO_ANNOTATIONS}\n",
    "for row in manifest.iterrows():\n",
    "    row = dict(row[1])\n",
    "    if row['video_uid'] not in VIDEO_UIDS_TO_METADATA:\n",
    "        continue\n",
    "    md = {\n",
    "        'video_duration_sec': row['canonical_video_duration_sec'],\n",
    "        'scenarios': ast.literal_eval(row['scenarios']),\n",
    "        'source': row['video_source'],\n",
    "    }\n",
    "    VIDEO_UIDS_TO_METADATA[row['video_uid']] = md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute hours of video annotated\n",
    "coverage_stats = vq_stats.compute_coverage_statistics(\n",
    "    VIDEO_ANNOTATIONS, VIDEO_UIDS_TO_METADATA\n",
    ")\n",
    "print('-' * 50)\n",
    "print(\"Video coverage statistics\")\n",
    "print('-' * 50)\n",
    "for k, v in coverage_stats.items():\n",
    "    print(f\"{k:<15s}: {v:.3f} hours\")\n",
    "# Compute number of clips annotated\n",
    "clip_stats = vq_stats.compute_clip_statistics(VIDEO_ANNOTATIONS)\n",
    "print('-' * 50)\n",
    "print(\"Clip statistics\")\n",
    "print('-' * 50)\n",
    "for k, v in clip_stats.items():\n",
    "    print(f\"{k:<15s}: {v:>5d}\")\n",
    "# Compute number of visual queries annotated\n",
    "query_stats = vq_stats.compute_query_statistics(VIDEO_ANNOTATIONS)\n",
    "print('-' * 50)\n",
    "print(\"Query statistics\")\n",
    "print('-' * 50)\n",
    "for k, v in query_stats.items():\n",
    "    print(f\"{k:<15s}: {v:>5d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print histogram over clip lengths in minutes\n",
    "clip_lengths = []\n",
    "for v in VIDEO_ANNOTATIONS:\n",
    "    for c in v['clips']:\n",
    "        if c['annotation_complete']:\n",
    "            cl = (c['video_end_sec'] - c['video_start_sec']) / 60.0\n",
    "            clip_lengths.append(cl)\n",
    "\n",
    "vq_stats.hist(\n",
    "    clip_lengths,\n",
    "    rwidth=0.8,\n",
    "    title=f'Histogram over clip lengths',\n",
    "    xlabel='Clip length (minutes)', ylabel='# clips annotated',\n",
    "    color=\"dodgerblue\",\n",
    "    edgecolor=\".8\",\n",
    "    figsize=(6, 6),\n",
    "    add_grid=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scenario coverage statistics\n",
    "scenarios_coverage = vq_stats.compute_scenario_coverage_statistics(\n",
    "    VIDEO_ANNOTATIONS, VIDEO_UIDS_TO_METADATA\n",
    ")\n",
    "sorted_scenarios_coverage = sorted(\n",
    "    scenarios_coverage.items(), key=lambda x: x[1], reverse=True\n",
    ")\n",
    "vq_stats.barplot(\n",
    "    x=[\n",
    "        s[:23] if len(s) <= 23 else s[:20] + \"...\"\n",
    "        for s, c in sorted_scenarios_coverage\n",
    "    ],\n",
    "    y=[c for s, c in sorted_scenarios_coverage],\n",
    "    rotation=90,\n",
    "    xlabel=\"Scenarios\",\n",
    "    ylabel=\"# video hours\",\n",
    "    color=\"dodgerblue\",\n",
    "    edgecolor=\".8\",\n",
    "    figsize=(22, 7),\n",
    "    title=f\"Total: scenarios={len(sorted_scenarios_coverage)}, hours={coverage_stats['total_coverage']:.2f}\",\n",
    "    add_grid=True,\n",
    "    save_path=os.path.join(STATS_DIR, \"ego4d-vq-scenarios.png\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot university coverage statistics\n",
    "universities_coverage = vq_stats.compute_university_coverage_statistics(\n",
    "    VIDEO_ANNOTATIONS, VIDEO_UIDS_TO_METADATA\n",
    ")\n",
    "sorted_universities_coverage = sorted(\n",
    "    universities_coverage.items(), key=lambda x: x[1], reverse=True\n",
    ")\n",
    "vq_stats.barplot(\n",
    "    x=[\n",
    "        s[:20] if len(s) <= 20 else s[:20] + \"...\"\n",
    "        for s, c in sorted_universities_coverage\n",
    "    ],\n",
    "    y=[c for s, c in sorted_universities_coverage],\n",
    "    rotation=90,\n",
    "    xlabel=\"Universities\",\n",
    "    ylabel=\"# video hours\",\n",
    "    color=\"dodgerblue\",\n",
    "    edgecolor=\".8\",\n",
    "    figsize=(8, 6),\n",
    "    title=f\"Total: universities={len(sorted_universities_coverage)}, hours={coverage_stats['total_coverage']:.2f}\",\n",
    "    add_grid=True,\n",
    "    save_path=os.path.join(STATS_DIR, \"ego4d-vq-universities.png\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze biases in the data\n",
    "\n",
    "* Bias 1: Separation b/w the query frame and response track\n",
    "* Bias 2: Size of the response track\n",
    "* Bias 3: Location of bboxes in the RT images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "# Bias 1: Separation b/w the query frame and response track\n",
    "##################################################################################\n",
    "\n",
    "q2r_separation = vq_stats.compute_query_to_response_separation_statistics(\n",
    "    VIDEO_ANNOTATIONS\n",
    ")\n",
    "\n",
    "vq_stats.hist(\n",
    "    x=q2r_separation,\n",
    "    xlabel=\"Separation b/w query and response track (# frames)\", \n",
    "    ylabel=\"# annotations\",\n",
    "    color=\"dodgerblue\",\n",
    "    edgecolor=\".8\",\n",
    "    bins=500,\n",
    "    xlim=[0, 600],\n",
    "    ylim=[0, 5000],\n",
    "    figsize=(7, 6),\n",
    "    add_grid=True,\n",
    "    save_path=os.path.join(STATS_DIR, \"ego4d-biases-q2r.png\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "# Bias 2: Size of the response track\n",
    "##################################################################################\n",
    "\n",
    "rt_sizes = vq_stats.compute_response_track_length_statistics(\n",
    "    VIDEO_ANNOTATIONS\n",
    ")\n",
    "\n",
    "vq_stats.hist(\n",
    "    x=rt_sizes,\n",
    "    xlabel=\"Response track sizes (# frames)\", \n",
    "    ylabel=\"# annotations\",\n",
    "    color=\"dodgerblue\",\n",
    "    edgecolor=\".8\",\n",
    "    bins=300,\n",
    "    ylim=[0, 5000],\n",
    "    xlim=[0, 100],\n",
    "    figsize=(7, 6),\n",
    "    add_grid=True,\n",
    "    save_path=os.path.join(STATS_DIR, \"ego4d-biases-rtsize.png\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "# Bias 3: Location of bboxes in the RT images\n",
    "##################################################################################\n",
    "\n",
    "rt_bbox_locations = vq_stats.compute_response_track_location_statistics(\n",
    "    VIDEO_ANNOTATIONS,\n",
    ")\n",
    "# Create density image\n",
    "H, W = 1080, 1920\n",
    "density_image = np.zeros((H, W))\n",
    "for xs, ys, xe, ye in rt_bbox_locations:\n",
    "    xs, ys, xe, ye = int(xs * W), int(ys * H), int(xe * W), int(ye * H)\n",
    "    density_image[ys : ye + 1, xs : xe + 1] += 1\n",
    "\n",
    "plt.figure(figsize=(11, 5.5))\n",
    "plt.imshow(density_image / density_image.max())\n",
    "plt.colorbar()\n",
    "plt.savefig(os.path.join(STATS_DIR, \"ego4d-biases-rtlocs.png\"))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "357b856e98ffd48e80f71546cd971c190cc1819dadad54d7736d44773b369b83"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ego4d_repro')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
